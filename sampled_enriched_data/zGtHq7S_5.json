{
  "id": "zGtHq7S_5",
  "conversations": [
    {
      "from": "gpt",
      "value": "Here's a Python code that generates the tables and saves them to an XML file named 'statistics.xml':\n```python\nimport xml.etree.ElementTree as ET\n\n# Create root element of the XML file\nroot = ET.Element('statistics')\n\n# Create tables for recall rate and angle accuracy\nrecall_table = ET.SubElement(root, 'table', name='recall_rate')\nangle_table = ET.SubElement(root, 'table', name='angle_accuracy')\n\n# Define distances and angles\ndistances = [0, 30, 60, 90, 120, 150, 180]\nangles = [0, 15, 30, 45, 60, 75, 90]\n\n# Loop through each distance and angle to add values to the tables\nfor distance in distances:\n    # Create row for the distance in both tables\n    recall_row = ET.SubElement(recall_table, 'row', name=str(distance))\n    angle_row = ET.SubElement(angle_table, 'row', name=str(distance))\n    \n    for angle in angles:\n        # Extract recall rate and angle accuracy from the text\n        text = \"\"\"\n        dist = {}, thres = {}\n        0 degree: <45 = 10/10, >45 = 0/10\n        15 degree: <45 = 10/10, >45 = 0/10\n        30 degree: <45 = 7/10, >45 = 3/10\n        45 degree: <45 = 10/10, >45 = 0/10\n        60 degree: <45 = 10/10, >45 = 0/10\n        75 degree: <45 = 6/10, >45 = 4/10\n        90 degree: <45 = 4/10, >45 = 6/10\n        fp num = 33/70\n        \"\"\"\n        start_index = text.index(\"{} degree: <45\".format(angle))\n        end_index = text.index(\"\\n\", start_index)\n        values = text[start_index:end_index].split(\"= \")[1].split(\", \")\n        below_45 = values[0].split(\"/\")\n        above_45 = values[1].split(\"/\")\n        \n        # Calculate recall rate and angle accuracy\n        recall_rate = int(below_45[0]) / 10\n        if angle < 45:\n            angle_accuracy = int(below_45[0]) / int(below_45[1])\n        else:\n            angle_accuracy = int(above_45[0]) / int(above_45[1])\n        \n        # Add recall rate and angle accuracy to the tables\n        ET.SubElement(recall_row, 'column', name=str(angle)).text = \"{:.2f}\".format(recall_rate)\n        ET.SubElement(angle_row, 'column', name=str(angle)).text = \"{:.2f}\".format(angle_accuracy)\n\n# Write the XML file\ntree = ET.ElementTree(root)\ntree.write('statistics.xml')\n```\nNote: The text in the code above is the same as the sample text provided in the question. To use actual data, replace the `text` variable with the actual text data.",
      "language": "en",
      "sentiment": {
        "neg": 0.0,
        "neu": 0.962,
        "pos": 0.038,
        "compound": 0.8658
      },
      "core_lexical": {
        "self_ref_freq": 0,
        "second_person_freq": 0,
        "token_count": 535,
        "self_ref_ratio": 0.0,
        "second_person_ratio": 0.0
      },
      "lexical_features": {
        "adj_adv_freq": 44,
        "adj_adv_ratio": 0.08224299065420561,
        "self_ref_freq": 0,
        "self_ref_ratio": 0.0,
        "second_person_freq": 0,
        "second_person_ratio": 0.0,
        "token_count": 535
      },
      "advanced_features": {
        "structural_features": {
          "avg_sentence_length": 267.5,
          "clause_complexity": 0.5,
          "vocabulary_richness": 0.36942675159235666
        },
        "interaction_features": {
          "question_types": {
            "what": 0,
            "how": 0,
            "why": 0,
            "can_could": 0,
            "general": 0
          },
          "discourse_markers": {
            "elaboration": 0,
            "contrast": 0,
            "causality": 0,
            "hedging": 0
          }
        },
        "linguistic_features": {
          "verb_tense_dist": {
            "VBZ": 8,
            "VBN": 2,
            "VB": 6,
            "VBP": 11,
            "VBD": 8
          },
          "named_entities": {
            "GPE": 2,
            "ORGANIZATION": 7
          }
        }
      }
    },
    {
      "from": "human",
      "value": "How about Modify the python code to save the statistics into .xlsx format.",
      "language": "en",
      "sentiment": {
        "neg": 0.0,
        "neu": 0.789,
        "pos": 0.211,
        "compound": 0.4939
      },
      "core_lexical": {
        "self_ref_freq": 0,
        "second_person_freq": 0,
        "token_count": 14,
        "self_ref_ratio": 0.0,
        "second_person_ratio": 0.0
      },
      "lexical_features": {
        "adj_adv_freq": 2,
        "adj_adv_ratio": 0.14285714285714285,
        "self_ref_freq": 0,
        "self_ref_ratio": 0.0,
        "second_person_freq": 0,
        "second_person_ratio": 0.0,
        "token_count": 14
      },
      "advanced_features": {
        "structural_features": {
          "avg_sentence_length": 14.0,
          "clause_complexity": 0.0,
          "vocabulary_richness": 1.0
        },
        "interaction_features": {
          "question_types": {
            "what": 0,
            "how": 1,
            "why": 0,
            "can_could": 0,
            "general": 0
          },
          "discourse_markers": {
            "elaboration": 0,
            "contrast": 0,
            "causality": 0,
            "hedging": 0
          }
        },
        "linguistic_features": {
          "verb_tense_dist": {
            "VB": 1
          },
          "named_entities": {}
        }
      },
      "expressive_label": 0,
      "anthropomorphic_label": 0
    },
    {
      "from": "gpt",
      "value": "Sure, here's the modified code to save the statistics into an .xlsx file using the `openpyxl` library:\n```python\nimport openpyxl\n\n# create a new workbook and select the active worksheet\nworkbook = openpyxl.Workbook()\nworksheet = workbook.active\n\n# set column names\ndistance = [0, 30, 60, 90, 120, 150, 180]\nfor i in range(len(distance)):\n    worksheet.cell(row=1, column=i+2, value=distance[i])\n\n# set row names\nangle = [0, 15, 30, 45, 60, 75, 90]\nfor i in range(len(angle)):\n    worksheet.cell(row=i+2, column=1, value=angle[i])\n\n# read statistics from text file\nwith open('statistics.txt', 'r') as file:\n    stats = file.read()\n\n# parse statistics into a dictionary\ntable = {}\nfor line in stats.split('\\n'):\n    if line.startswith('dist'):\n        dist = int(line.split('=')[1].strip())\n        table[dist] = {'recall': {}, 'accuracy': {}}\n    elif line.startswith('fp'):\n        fp_num = line.split('=')[1].strip()\n        table[dist]['fp_num'] = fp_num\n    elif line:\n        angle_line, recall_line, accuracy_line = line.split(':')\n        angle = int(angle_line.strip().split()[0])\n        recall_lt_45, recall_gt_45 = recall_line.strip().split(',')\n        accuracy_lt_45, accuracy_gt_45 = accuracy_line.strip().split(',')\n        table[dist]['recall'][angle] = {'<45': int(recall_lt_45.split('=')[1].strip()) / 10,\n                                        '>45': int(recall_gt_45.split('=')[1].strip()) / 10}\n        table[dist]['accuracy'][angle] = {'<45': float(accuracy_lt_45.split('=')[1].strip()),\n                                           '>45': float(accuracy_gt_45.split('=')[1].strip())}\n\n# fill in the table\nfor row in range(2, 9):\n    for col in range(2, 9):\n        dist = distance[col-2]\n        angle = angle[row-2]\n        worksheet.cell(row=row, column=col, value=table[dist]['recall'][angle]['>45'])\n        if angle < 45:\n            worksheet.cell(row=row, column=col, value=table[dist]['accuracy'][angle]['<45'])\n        else:\n            worksheet.cell(row=row, column=col, value=table[dist]['accuracy'][angle]['>45'])\n\n# save the workbook\nworkbook.save('statistics.xlsx')\n```\nThis code reads the statistics from the text file, parses them into a dictionary, and then fills in the appropriate cells in the Excel worksheet. The resulting worksheet is then saved as an .xlsx file. Note that you'll need to have the `openpyxl` library installed to run this code.",
      "language": "en",
      "sentiment": {
        "neg": 0.0,
        "neu": 0.925,
        "pos": 0.075,
        "compound": 0.9538
      },
      "core_lexical": {
        "self_ref_freq": 6,
        "second_person_freq": 1,
        "token_count": 594,
        "self_ref_ratio": 0.010101010101010102,
        "second_person_ratio": 0.0016835016835016834
      },
      "lexical_features": {
        "adj_adv_freq": 48,
        "adj_adv_ratio": 0.08080808080808081,
        "self_ref_freq": 6,
        "self_ref_ratio": 0.010101010101010102,
        "second_person_freq": 1,
        "second_person_ratio": 0.0016835016835016834,
        "token_count": 594
      },
      "advanced_features": {
        "structural_features": {
          "avg_sentence_length": 198.0,
          "clause_complexity": 0.6666666666666666,
          "vocabulary_richness": 0.4589041095890411
        },
        "interaction_features": {
          "question_types": {
            "what": 0,
            "how": 0,
            "why": 0,
            "can_could": 0,
            "general": 0
          },
          "discourse_markers": {
            "elaboration": 0,
            "contrast": 0,
            "causality": 0,
            "hedging": 0
          }
        },
        "linguistic_features": {
          "verb_tense_dist": {
            "VBZ": 5,
            "VB": 8,
            "VBG": 2,
            "VBN": 6,
            "VBP": 14,
            "VBD": 2
          },
          "named_entities": {
            "ORGANIZATION": 1
          }
        }
      }
    }
  ],
  "overall_sentiment": {
    "compound": 0.7711666666666668,
    "pos": 0.108,
    "neu": 0.892,
    "neg": 0.0
  },
  "overall_lexical": {
    "adj_adv_freq": 94,
    "adj_adv_ratio": 0.08223972003499562,
    "self_ref_freq": 6,
    "self_ref_ratio": 0.005249343832020997,
    "second_person_freq": 1,
    "second_person_ratio": 0.0008748906386701663,
    "total_tokens": 1143
  },
  "overall_advanced": {
    "structural_features": {
      "avg_sentence_length": 159.83333333333334,
      "clause_complexity": 0.38888888888888884,
      "vocabulary_richness": 0.6094436203937993
    },
    "interaction_features": {
      "question_types": {
        "what": 0,
        "how": 1,
        "why": 0,
        "can_could": 0,
        "general": 0
      },
      "discourse_markers": {
        "elaboration": 0,
        "contrast": 0,
        "causality": 0,
        "hedging": 0
      }
    },
    "linguistic_features": {
      "verb_tense_dist": {
        "VBZ": 13,
        "VBN": 8,
        "VB": 15,
        "VBP": 25,
        "VBD": 10,
        "VBG": 2
      },
      "named_entities": {
        "GPE": 2,
        "ORGANIZATION": 8
      }
    }
  },
  "conversation_metadata": {
    "language_distribution": {
      "en": 3
    },
    "turn_count": 3,
    "total_tokens": 1143
  }
}